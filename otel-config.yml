
receivers:
    prometheus:
        config:
            scrape_configs:
                - job_name: "prosody"
                  scrape_interval: 120s
                  static_configs:
                      - targets: ["prosody:5280"] # Assumes Prosody service is named 'prosody' on the Docker network
                  metrics_path: "/metrics"

                - job_name: "jicofo"
                  scrape_interval: 120s
                  static_configs:
                      - targets: ["jicofo:8888"] # Assumes Jicofo service is named 'jicofo'
                  metrics_path: "/metrics"

                - job_name: "jvb"
                  scrape_interval: 120s
                  static_configs:
                      - targets: ["jvb:8080"] # Assumes JVB service is named 'jvb'
                  metrics_path: "/metrics"

                - job_name: "keycloak"
                  scrape_interval: 180s
                  static_configs:
                      - targets: ["keycloak:9000"] # Assumes Keycloak service name and port
                  metrics_path: "/metrics"

                - job_name: "otel-collector"
                  scrape_interval: 60s
                  static_configs:
                      - targets: ["localhost:8889"] # Internal port for collector's metrics
                  metrics_path: "/metrics"

    filelog:
        include:
            - /var/lib/docker/containers/*/*-json.log # Standard Docker JSON log files
        include_file_path: true
        start_at: end
        poll_interval: 5s
        operators:
            - type: container # Use the new container operator
              # format: docker # Optional: format can be auto-detected
              # add_metadata_from_filepath: false # For non-k8s, filepath metadata extraction is less relevant
        # Add labels for discovered log files to help identify them. These are added to the log record itself.
        resource:
            container.name: $$.attributes["log.file.path_resolved"].basename().replace("-json.log", "") # Experimental: trying to get container ID

processors:
    batch: {}

    resourcedetection:
        detectors: ["env", "system", "docker"]
        override: false

    transform/drop_unneeded_resource_attributes:
        error_mode: ignore
        metric_statements:
            - context: resource
              statements:
                  - delete_key(attributes, "k8s.pod.start_time")
                  - delete_key(attributes, "os.description")
                  - delete_key(attributes, "os.type")
                  - delete_key(attributes, "process.command_args")
                  - delete_key(attributes, "process.executable.path")
                  - delete_key(attributes, "process.pid")
                  - delete_key(attributes, "process.runtime.description")
                  - delete_key(attributes, "process.runtime.name")
                  - delete_key(attributes, "process.runtime.version")
                  # Host related attributes that might be redundant if host.name is present
                  - delete_key(attributes, "host.arch")
                  - delete_key(attributes, "host.cpu.model.name")
                  - delete_key(attributes, "host.cpu.vendor.id")
                  # Container specific attributes if not needed at this stage
                  - delete_key(attributes, "container.id")
                  - delete_key(attributes, "container.image.name")
                  - delete_key(attributes, "container.image.tag")
                  - delete_key(attributes, "container.runtime")

    transform/add_resource_attributes_as_metric_attributes:
        error_mode: ignore
        metric_statements:
            - context: datapoint
              statements:
                  - set(attributes["deployment.environment"], resource.attributes["deployment.environment"]) # Assuming deployment.environment is an env var
                  - set(attributes["service.version"], resource.attributes["service.version"]) # Assuming service.version is an env var
                  - set(attributes["host.name"], resource.attributes["host.name"])
                  - set(attributes["service.name"], resource.attributes["service.name"])
        log_statements:
            - context: resource
              statements:
                  - keep_keys(attributes, [
                    "deployment.environment",
                    "service.version",
                    "host.name",
                    "service.name",
                    "container.name",
                    "container.id",
                    "container.image.name",
                    "log.file.path_resolved"
                    ])

exporters:
    otlphttp/grafana_cloud:
        endpoint: "https://otlp-gateway-prod-eu-west-2.grafana.net/otlp"
        auth:
            authenticator: basicauth/grafana_cloud

extensions:
    basicauth/grafana_cloud:
        client_auth:
            username: "${GRAFANA_USERNAME}"
            password: "${GRAFANA_API_KEY}"

service:
    extensions: [basicauth/grafana_cloud]
    telemetry:
        metrics:
            level: basic
            address: 0.0.0.0:8889
    pipelines:
        metrics:
            receivers: [prometheus]
            processors:
                - resourcedetection
                - transform/drop_unneeded_resource_attributes
                - transform/add_resource_attributes_as_metric_attributes
                - batch
            exporters: [otlphttp/grafana_cloud]
        logs:
            receivers: [filelog]
            processors:
                - resourcedetection
                - transform/drop_unneeded_resource_attributes
                - transform/add_resource_attributes_as_metric_attributes
                - batch
            exporters: [otlphttp/grafana_cloud]
